{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d662870",
   "metadata": {},
   "source": [
    "Instalamos las librerias necesarias (Python 3.13.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39314da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (20250625)\n",
      "Requirement already satisfied: librosa in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: pydub in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (0.25.1)\n",
      "Requirement already satisfied: scikit-learn in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (1.7.2)\n",
      "Collecting speechrecognition\n",
      "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: ipykernel in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (6.30.1)\n",
      "Requirement already satisfied: more-itertools in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (10.8.0)\n",
      "Requirement already satisfied: numba in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (0.62.1)\n",
      "Requirement already satisfied: numpy in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (2.3.3)\n",
      "Requirement already satisfied: tiktoken in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (0.11.0)\n",
      "Requirement already satisfied: torch in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (2.8.0)\n",
      "Requirement already satisfied: tqdm in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from openai-whisper) (3.4.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: standard-aifc in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: audioop-lts in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from speechrecognition) (0.2.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=25 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from jupyter-client>=8.0.0->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.4.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from numba->openai-whisper) (0.45.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from triton>=2->openai-whisper) (78.1.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: standard-chunk in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from tiktoken->openai-whisper) (2025.9.18)\n",
      "Requirement already satisfied: filelock in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (3.19.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from torch->openai-whisper) (1.13.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hm/anaconda3/envs/audio2text/lib/python3.13/site-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
      "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: speechrecognition\n",
      "Successfully installed speechrecognition-3.14.3\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-whisper librosa pydub scikit-learn speechrecognition ipykernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0a6fc",
   "metadata": {},
   "source": [
    "Importamos las librerias necesarias y creamos las funciones que necesitamos para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff09939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando procesamiento de audio...\n",
      "Convirtiendo MP3 a WAV...\n",
      "Cargando modelo Whisper (base)...\n",
      "Transcribiendo audio...\n",
      "Procesando segmentos por hablantes...\n",
      "Transcripción guardada en: transcripcion_reunion.txt\n",
      "\n",
      "--- ESTADÍSTICAS ---\n",
      "Total de segmentos: 40\n",
      "Segmentos Persona_01: 40\n",
      "Segmentos Persona_02: 0\n",
      "Duración total: 122.0 segundos\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import speech_recognition as sr\n",
    "\n",
    "def convert_mp3_to_wav(mp3_path):\n",
    "    \"\"\"Convierte MP3 a WAV manteniendo la calidad\"\"\"\n",
    "    wav_path = mp3_path.replace('.mp3', '_converted.wav')\n",
    "    audio = AudioSegment.from_mp3(mp3_path)\n",
    "    # Convertir a mono y 16kHz para mejor procesamiento\n",
    "    audio = audio.set_channels(1).set_frame_rate(16000)\n",
    "    audio.export(wav_path, format='wav')\n",
    "    return wav_path\n",
    "\n",
    "def extract_audio_features(audio_path):\n",
    "    \"\"\"Extrae características del audio para clustering de hablantes\"\"\"\n",
    "    y, sr = librosa.load(audio_path, sr=16000)\n",
    "    \n",
    "    # Extraer MFCCs (características comunes para identificación de voz)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    \n",
    "    # Combinar características\n",
    "    features = np.vstack([mfcc, mfcc_delta, mfcc_delta2])\n",
    "    return features.T, sr\n",
    "\n",
    "def simple_speaker_diarization(audio_path, num_speakers=2):\n",
    "    \"\"\"Diarización simple basada en características de audio\"\"\"\n",
    "    features, sr = extract_audio_features(audio_path)\n",
    "    \n",
    "    # Usar clustering jerárquico para identificar hablantes\n",
    "    clustering = AgglomerativeClustering(n_clusters=num_speakers)\n",
    "    labels = clustering.fit_predict(features)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def transcribe_with_speakers(audio_path):\n",
    "    \"\"\"Transcripción con identificación básica de hablantes\"\"\"\n",
    "    \n",
    "    # 1. Convertir a WAV si es MP3\n",
    "    if audio_path.endswith('.mp3'):\n",
    "        print(\"Convirtiendo MP3 a WAV...\")\n",
    "        audio_path = convert_mp3_to_wav(audio_path)\n",
    "    \n",
    "    # 2. Cargar modelo ligero de Whisper (optimizado para CPU)\n",
    "    print(\"Cargando modelo Whisper (base)...\")\n",
    "    model = whisper.load_model(\"base\")  # Usar 'base' para CPU\n",
    "    \n",
    "    # 3. Transcribir el audio completo\n",
    "    print(\"Transcribiendo audio...\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    \n",
    "    # 4. Procesar segmentos y agrupar por hablantes aproximados\n",
    "    print(\"Procesando segmentos por hablantes...\")\n",
    "    \n",
    "    # Agrupar segmentos consecutivos por similitud temporal\n",
    "    segments = result[\"segments\"]\n",
    "    speaker_segments = []\n",
    "    current_speaker = \"Persona_01\"\n",
    "    \n",
    "    for i, segment in enumerate(segments):\n",
    "        if i == 0:\n",
    "            # Primer segmento\n",
    "            speaker_segments.append({\n",
    "                \"speaker\": current_speaker,\n",
    "                \"text\": segment[\"text\"],\n",
    "                \"start\": segment[\"start\"],\n",
    "                \"end\": segment[\"end\"]\n",
    "            })\n",
    "        else:\n",
    "            # Cambiar de hablante si hay una pausa significativa\n",
    "            prev_segment = segments[i-1]\n",
    "            pause_duration = segment[\"start\"] - prev_segment[\"end\"]\n",
    "            \n",
    "            if pause_duration > 2.0:  # Pausa de más de 2 segundos\n",
    "                current_speaker = \"Persona_02\" if current_speaker == \"Persona_01\" else \"Persona_01\"\n",
    "            \n",
    "            speaker_segments.append({\n",
    "                \"speaker\": current_speaker,\n",
    "                \"text\": segment[\"text\"],\n",
    "                \"start\": segment[\"start\"],\n",
    "                \"end\": segment[\"end\"]\n",
    "            })\n",
    "    \n",
    "    return speaker_segments\n",
    "\n",
    "def save_transcription(segments, output_file=\"transcripcion_reunion.txt\"):\n",
    "    \"\"\"Guarda la transcripción en formato legible\"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"TRANSCRIPCIÓN DE REUNIÓN - EQUIPO DE SEGURIDAD E INFRAESTRUCTURA\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "        \n",
    "        for segment in segments:\n",
    "            f.write(f\"{segment['speaker']} ({segment['start']:.1f}s - {segment['end']:.1f}s):\\n\")\n",
    "            f.write(f\"  {segment['text']}\\n\\n\")\n",
    "    \n",
    "    print(f\"Transcripción guardada en: {output_file}\")\n",
    "\n",
    "# Script principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuración\n",
    "    audio_file = \"ejemplo.mp3\"  # Cambia por tu archivo\n",
    "    output_file = \"transcripcion_reunion.txt\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Iniciando procesamiento de audio...\")\n",
    "        \n",
    "        # Procesar audio y transcribir\n",
    "        segments = transcribe_with_speakers(audio_file)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        save_transcription(segments, output_file)\n",
    "        \n",
    "        # Mostrar estadísticas\n",
    "        total_segments = len(segments)\n",
    "        persona1_segments = len([s for s in segments if s[\"speaker\"] == \"Persona_01\"])\n",
    "        persona2_segments = total_segments - persona1_segments\n",
    "        \n",
    "        print(f\"\\n--- ESTADÍSTICAS ---\")\n",
    "        print(f\"Total de segmentos: {total_segments}\")\n",
    "        print(f\"Segmentos Persona_01: {persona1_segments}\")\n",
    "        print(f\"Segmentos Persona_02: {persona2_segments}\")\n",
    "        print(f\"Duración total: {segments[-1]['end']:.1f} segundos\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el procesamiento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc1e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio2text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
